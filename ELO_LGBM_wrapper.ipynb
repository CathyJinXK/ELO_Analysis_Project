{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_pred.csv')\n",
    "test = pd.read_csv('test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 1741)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.columns.tolist()[0], axis = 1)\n",
    "test  = test.drop(test.columns.tolist()[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_wrapper(train, test):\n",
    "    print('Feaure selection wrapper working')\n",
    "    \n",
    "    name = 'card_id'\n",
    "    label = 'target'\n",
    "    features = train.columns.tolist()\n",
    "    features.remove(name)\n",
    "    features.remove(label)\n",
    "    \n",
    "    params_initial = {\n",
    "        'num_leaves': 31\n",
    "        , 'learning_rate': 0.1\n",
    "        , 'boosting': 'gbdt'\n",
    "        , 'min_child_samples': 20\n",
    "        , 'bagging_seed': 99\n",
    "        , 'bagging_fraction': 0.7\n",
    "        , 'bagging_freq': 1\n",
    "        , 'feature_fraction': 0.7\n",
    "        , 'max_depth': -1\n",
    "        , 'metric': 'rmse'\n",
    "        , 'reg_alpha': 0\n",
    "        , 'reg_lambda': 1\n",
    "        , 'objective': 'regression'\n",
    "    \n",
    "    }\n",
    "    ESR, NBR, VBE = 30, 10000, 50\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=99, shuffle=True)\n",
    "    fse = pd.Series(0, index= features)\n",
    "    \n",
    "    for train_part_idx, eval_idx in kf.split(train[features], train[label]):\n",
    "        \n",
    "        train_part = lgbm.Dataset(train[features].loc[train_part_idx], train[label].loc[train_part_idx])\n",
    "        eval_part = lgbm.Dataset(train[features].loc[eval_idx], train[label].loc[eval_idx])\n",
    "        \n",
    "        bst = lgbm.train(params_initial, train_part, valid_sets=[train_part, eval_part], valid_names=['train', 'eval']\n",
    "                         , early_stopping_rounds=ESR, keep_training_booster=NBR, verbose_eval= VBE\n",
    "        )\n",
    "        \n",
    "        fse += pd.Series(bst.feature_importance(),index=features)\n",
    "        \n",
    "        feature_selection = fse.sort_values(ascending=False).index.tolist()[:300]\n",
    "    \n",
    "    fse.to_csv('feature_importance_wrapper.csv')\n",
    "    print('FSW complete')\n",
    "    return train[[name] + feature_selection + [label]], test[[name] + feature_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feaure selection wrapper working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227186\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1629\n",
      "[LightGBM] [Info] Start training from score -0.387603\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.42335\teval's rmse: 3.756\n",
      "[100]\ttrain's rmse: 3.30229\teval's rmse: 3.75255\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.30229\teval's rmse: 3.75255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.337305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 226970\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 1628\n",
      "[LightGBM] [Info] Start training from score -0.391308\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.44786\teval's rmse: 3.68799\n",
      "[100]\ttrain's rmse: 3.32862\teval's rmse: 3.68532\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.32862\teval's rmse: 3.68532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.331487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227038\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1629\n",
      "[LightGBM] [Info] Start training from score -0.396074\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.45028\teval's rmse: 3.68793\n",
      "[100]\ttrain's rmse: 3.33537\teval's rmse: 3.68746\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.33537\teval's rmse: 3.68746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.375702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227071\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1625\n",
      "[LightGBM] [Info] Start training from score -0.399754\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.46316\teval's rmse: 3.6492\n",
      "[100]\ttrain's rmse: 3.34088\teval's rmse: 3.64922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.34088\teval's rmse: 3.64922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.399406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 227014\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 1628\n",
      "[LightGBM] [Info] Start training from score -0.393443\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.44574\teval's rmse: 3.67141\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttrain's rmse: 3.42506\teval's rmse: 3.67049\n",
      "FSW complete\n"
     ]
    }
   ],
   "source": [
    "train_LGBMwrapper, test_LGBMwrapper = feature_selection_wrapper(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_imp_wrap = pd.read_csv('feature_importance_wrapper.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "##### feature_imp_wrap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1740.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.172757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1740.000000\n",
       "mean      7.258621\n",
       "std      15.172757\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       8.000000\n",
       "max     212.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_wrap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.800e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.700e+01, 1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.800e+01, 1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01,\n",
       "         1.700e+01, 1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01, 1.700e+01,\n",
       "         1.700e+01, 1.800e+01, 1.700e+01, 1.800e+01],\n",
       "        [1.492e+03, 1.740e+02, 5.000e+01, 9.000e+00, 6.000e+00, 2.000e+00,\n",
       "         2.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "         1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]]),\n",
       " array([   0.  ,   17.39,   34.78,   52.17,   69.56,   86.95,  104.34,\n",
       "         121.73,  139.12,  156.51,  173.9 ,  191.29,  208.68,  226.07,\n",
       "         243.46,  260.85,  278.24,  295.63,  313.02,  330.41,  347.8 ,\n",
       "         365.19,  382.58,  399.97,  417.36,  434.75,  452.14,  469.53,\n",
       "         486.92,  504.31,  521.7 ,  539.09,  556.48,  573.87,  591.26,\n",
       "         608.65,  626.04,  643.43,  660.82,  678.21,  695.6 ,  712.99,\n",
       "         730.38,  747.77,  765.16,  782.55,  799.94,  817.33,  834.72,\n",
       "         852.11,  869.5 ,  886.89,  904.28,  921.67,  939.06,  956.45,\n",
       "         973.84,  991.23, 1008.62, 1026.01, 1043.4 , 1060.79, 1078.18,\n",
       "        1095.57, 1112.96, 1130.35, 1147.74, 1165.13, 1182.52, 1199.91,\n",
       "        1217.3 , 1234.69, 1252.08, 1269.47, 1286.86, 1304.25, 1321.64,\n",
       "        1339.03, 1356.42, 1373.81, 1391.2 , 1408.59, 1425.98, 1443.37,\n",
       "        1460.76, 1478.15, 1495.54, 1512.93, 1530.32, 1547.71, 1565.1 ,\n",
       "        1582.49, 1599.88, 1617.27, 1634.66, 1652.05, 1669.44, 1686.83,\n",
       "        1704.22, 1721.61, 1739.  ]),\n",
       " <a list of 2 BarContainer objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(feature_imp_wrap, bins = 100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def params_append(params):\n",
    "    \n",
    "    params['feature_pre_filter'] = False\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'rmse'\n",
    "    params['bagging_seed'] = 99\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def param_hyperopt(train):\n",
    "    print('Parameter hyper optimization working')\n",
    "    \n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features.remove('target')\n",
    "    \n",
    "    train_data = lgbm.Dataset(train[features], train['target'])\n",
    "    \n",
    "    def hyperopt_objective(params):\n",
    "        params = params_append(params)\n",
    "        print(params)\n",
    "        \n",
    "        res = lgbm.cv(params, \n",
    "                      train_data,\n",
    "                      1000,\n",
    "                      nfold=2,\n",
    "                      stratified=False,\n",
    "                      shuffle=True,\n",
    "                      metrics='rmse',\n",
    "                      early_stopping_rounds=20,\n",
    "                      verbose_eval=False,\n",
    "                      show_stdv=False,\n",
    "                      seed=99)\n",
    "        \n",
    "        return min(res['rmse-mean'])\n",
    "    \n",
    "    params_space = {\n",
    "        'learning_rate': hp.uniform('learning_rate', 1e-2, 5e-1),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n",
    "        'num_leaves': hp.choice('num_leaves', list(range(10,301,10))),\n",
    "        'reg_alpha': hp.randint('reg_alpha', 0,10),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0,10),\n",
    "        'bagging_frequency': hp.randint('bagging_frequency', 0,10),\n",
    "        'min_child_samples': hp.choice('min_child_samples', list(range(1,31,5))),\n",
    "    }\n",
    "    \n",
    "    params_best = fmin(hyperopt_objective, \n",
    "                      space=params_space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=30,\n",
    "                       rstate=np.random.default_rng(99)\n",
    "                    )\n",
    "    return params_best\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter hyper optimization working\n",
      "{'bagging_fraction': 0.83394292426786, 'bagging_frequency': 3, 'feature_fraction': 0.5505176174601247, 'learning_rate': 0.04700622267515105, 'min_child_samples': 26, 'num_leaves': 90, 'reg_alpha': 2, 'reg_lambda': 3.87092153777453, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                    \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score -0.381506 \n",
      "[LightGBM] [Info] Start training from score -0.405767 \n",
      "  0%|          | 0/30 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.9386402440403612, 'bagging_frequency': 4, 'feature_fraction': 0.6306790074884632, 'learning_rate': 0.3591519852379942, 'min_child_samples': 16, 'num_leaves': 150, 'reg_alpha': 8, 'reg_lambda': 1.5769260367383686, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "  3%|â–Ž         | 1/30 [00:10<05:10, 10.70s/trial, best loss: 3.68237928373717]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Info] Start training from score -0.381506                         \n",
      "[LightGBM] [Info] Start training from score -0.405767                         \n",
      "{'bagging_fraction': 0.8891625960470265, 'bagging_frequency': 4, 'feature_fraction': 0.800936211274754, 'learning_rate': 0.15713929344213737, 'min_child_samples': 11, 'num_leaves': 10, 'reg_alpha': 9, 'reg_lambda': 9.945366399325135, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Info] Start training from score -0.381506                         \n",
      "[LightGBM] [Info] Start training from score -0.405767                         \n",
      "{'bagging_fraction': 0.9814794572646075, 'bagging_frequency': 7, 'feature_fraction': 0.5822466745718682, 'learning_rate': 0.3829002781291592, 'min_child_samples': 11, 'num_leaves': 150, 'reg_alpha': 1, 'reg_lambda': 7.843131118954708, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Info] Start training from score -0.381506                         \n",
      "[LightGBM] [Info] Start training from score -0.405767                         \n",
      "{'bagging_fraction': 0.7003872073844015, 'bagging_frequency': 4, 'feature_fraction': 0.5272897871028177, 'learning_rate': 0.11781953690954647, 'min_child_samples': 6, 'num_leaves': 40, 'reg_alpha': 0, 'reg_lambda': 2.167283592837154, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Info] Start training from score -0.381506                         \n",
      "[LightGBM] [Info] Start training from score -0.405767                         \n",
      "{'bagging_fraction': 0.713059682239195, 'bagging_frequency': 3, 'feature_fraction': 0.896944211391964, 'learning_rate': 0.041461009689890894, 'min_child_samples': 16, 'num_leaves': 30, 'reg_alpha': 1, 'reg_lambda': 6.5580188407170485, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                            \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                     \n",
      "[LightGBM] [Info] Start training from score -0.381506                         \n",
      "[LightGBM] [Info] Start training from score -0.405767                         \n",
      "{'bagging_fraction': 0.5544954081042264, 'bagging_frequency': 4, 'feature_fraction': 0.574253256231929, 'learning_rate': 0.41971336199340264, 'min_child_samples': 1, 'num_leaves': 300, 'reg_alpha': 5, 'reg_lambda': 5.780635350700095, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Info] Start training from score -0.381506                           \n",
      "[LightGBM] [Info] Start training from score -0.405767                           \n",
      "{'bagging_fraction': 0.9054015565137321, 'bagging_frequency': 4, 'feature_fraction': 0.8462129370173965, 'learning_rate': 0.2937464056762595, 'min_child_samples': 21, 'num_leaves': 100, 'reg_alpha': 7, 'reg_lambda': 8.820889345094663, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Info] Start training from score -0.381506                           \n",
      "[LightGBM] [Info] Start training from score -0.405767                           \n",
      "{'bagging_fraction': 0.9823643542294593, 'bagging_frequency': 3, 'feature_fraction': 0.8979249311019042, 'learning_rate': 0.456380118192351, 'min_child_samples': 21, 'num_leaves': 30, 'reg_alpha': 8, 'reg_lambda': 5.920269510325894, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Info] Start training from score -0.381506                           \n",
      "[LightGBM] [Info] Start training from score -0.405767                           \n",
      "{'bagging_fraction': 0.6677797029890983, 'bagging_frequency': 9, 'feature_fraction': 0.6447148456986164, 'learning_rate': 0.479371670608775, 'min_child_samples': 26, 'num_leaves': 260, 'reg_alpha': 4, 'reg_lambda': 9.998900849129054, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Info] Start training from score -0.381506                           \n",
      "[LightGBM] [Info] Start training from score -0.405767                           \n",
      "{'bagging_fraction': 0.5508840375841091, 'bagging_frequency': 1, 'feature_fraction': 0.8759078894115055, 'learning_rate': 0.23809501352360704, 'min_child_samples': 6, 'num_leaves': 100, 'reg_alpha': 2, 'reg_lambda': 2.5907834424746246, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.6756218142091266, 'bagging_frequency': 8, 'feature_fraction': 0.5772564826614565, 'learning_rate': 0.2766832211749316, 'min_child_samples': 1, 'num_leaves': 210, 'reg_alpha': 6, 'reg_lambda': 0.1271654869056582, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.5956090563303222, 'bagging_frequency': 4, 'feature_fraction': 0.5398927640353357, 'learning_rate': 0.15184643095729294, 'min_child_samples': 11, 'num_leaves': 60, 'reg_alpha': 7, 'reg_lambda': 3.723338343165059, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.7893655670980657, 'bagging_frequency': 2, 'feature_fraction': 0.8754515163189475, 'learning_rate': 0.18490787323048988, 'min_child_samples': 21, 'num_leaves': 10, 'reg_alpha': 0, 'reg_lambda': 4.672931347647053, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.8594249682173715, 'bagging_frequency': 1, 'feature_fraction': 0.7498711371435326, 'learning_rate': 0.13793625475318477, 'min_child_samples': 11, 'num_leaves': 30, 'reg_alpha': 5, 'reg_lambda': 7.7758291525858505, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.9392967346444276, 'bagging_frequency': 2, 'feature_fraction': 0.9328246322861229, 'learning_rate': 0.20772367703771233, 'min_child_samples': 6, 'num_leaves': 50, 'reg_alpha': 2, 'reg_lambda': 2.8689807332009165, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.6644567569124256, 'bagging_frequency': 0, 'feature_fraction': 0.8207841101261135, 'learning_rate': 0.040823577874232894, 'min_child_samples': 11, 'num_leaves': 260, 'reg_alpha': 2, 'reg_lambda': 8.707053136310382, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.537195779878404, 'bagging_frequency': 9, 'feature_fraction': 0.5714988814635541, 'learning_rate': 0.3902090729032495, 'min_child_samples': 11, 'num_leaves': 80, 'reg_alpha': 1, 'reg_lambda': 9.249236821220725, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.7285687913349613, 'bagging_frequency': 1, 'feature_fraction': 0.5543058554416358, 'learning_rate': 0.033924351009012504, 'min_child_samples': 16, 'num_leaves': 190, 'reg_alpha': 9, 'reg_lambda': 4.838256296514379, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.5084501653344959, 'bagging_frequency': 3, 'feature_fraction': 0.5345319116576943, 'learning_rate': 0.3425683128696361, 'min_child_samples': 26, 'num_leaves': 250, 'reg_alpha': 3, 'reg_lambda': 0.8633229070841597, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.796622870795799, 'bagging_frequency': 3, 'feature_fraction': 0.9937690636110825, 'learning_rate': 0.08978744675419864, 'min_child_samples': 16, 'num_leaves': 90, 'reg_alpha': 1, 'reg_lambda': 6.619984792502141, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.8197474436231942, 'bagging_frequency': 6, 'feature_fraction': 0.7326259969403444, 'learning_rate': 0.07299192041816045, 'min_child_samples': 26, 'num_leaves': 240, 'reg_alpha': 3, 'reg_lambda': 3.5804426924772477, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.7474581515832761, 'bagging_frequency': 5, 'feature_fraction': 0.9849904252554557, 'learning_rate': 0.011231512775057201, 'min_child_samples': 26, 'num_leaves': 230, 'reg_alpha': 2, 'reg_lambda': 7.101575487641395, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.8395513718294851, 'bagging_frequency': 3, 'feature_fraction': 0.6983072069512244, 'learning_rate': 0.0790238100086763, 'min_child_samples': 16, 'num_leaves': 140, 'reg_alpha': 1, 'reg_lambda': 4.16573912406113, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.6172005048055369, 'bagging_frequency': 3, 'feature_fraction': 0.932889211088657, 'learning_rate': 0.012989321712077104, 'min_child_samples': 26, 'num_leaves': 90, 'reg_alpha': 6, 'reg_lambda': 5.8734098983762415, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.6307038174628614, 'bagging_frequency': 3, 'feature_fraction': 0.9527990808980931, 'learning_rate': 0.11419427311236446, 'min_child_samples': 16, 'num_leaves': 70, 'reg_alpha': 6, 'reg_lambda': 5.977747516681239, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Info] Start training from score -0.381506                           \n",
      "[LightGBM] [Info] Start training from score -0.405767                           \n",
      "{'bagging_fraction': 0.6004493531200874, 'bagging_frequency': 0, 'feature_fraction': 0.9355161154164914, 'learning_rate': 0.01831982577679769, 'min_child_samples': 16, 'num_leaves': 110, 'reg_alpha': 6, 'reg_lambda': 7.13805385588623, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                              \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                       \n",
      "[LightGBM] [Info] Start training from score -0.381506                           \n",
      "[LightGBM] [Info] Start training from score -0.405767                           \n",
      "{'bagging_fraction': 0.5952605403411254, 'bagging_frequency': 0, 'feature_fraction': 0.7923580623789592, 'learning_rate': 0.017173228719162728, 'min_child_samples': 1, 'num_leaves': 110, 'reg_alpha': 6, 'reg_lambda': 7.920706102051057, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.5865083803891665, 'bagging_frequency': 0, 'feature_fraction': 0.79179978956375, 'learning_rate': 0.19566090935444358, 'min_child_samples': 1, 'num_leaves': 110, 'reg_alpha': 6, 'reg_lambda': 7.906229855101424, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "{'bagging_fraction': 0.5071446955487892, 'bagging_frequency': 0, 'feature_fraction': 0.7066461083488597, 'learning_rate': 0.01114741291316183, 'min_child_samples': 1, 'num_leaves': 110, 'reg_alpha': 6, 'reg_lambda': 7.094175717510358, 'feature_pre_filter': False, 'objective': 'regression', 'metric': 'rmse', 'bagging_seed': 99}\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66949                                               \n",
      "[LightGBM] [Info] Number of data points in the train set: 100958, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency                        \n",
      "[LightGBM] [Info] Start training from score -0.381506                            \n",
      "[LightGBM] [Info] Start training from score -0.405767                            \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [06:21<00:00, 12.71s/trial, best loss: 3.6750415341878884]\n"
     ]
    }
   ],
   "source": [
    "best_clf = param_hyperopt(train_LGBMwrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5071446955487892,\n",
       " 'bagging_frequency': 0,\n",
       " 'feature_fraction': 0.7066461083488597,\n",
       " 'learning_rate': 0.01114741291316183,\n",
       " 'min_child_samples': 0,\n",
       " 'num_leaves': 10,\n",
       " 'reg_alpha': 6,\n",
       " 'reg_lambda': 7.094175717510358}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66949\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.393636\n"
     ]
    }
   ],
   "source": [
    "best_clf = params_append(best_clf)\n",
    "\n",
    "features = train_LGBMwrapper.columns.tolist()\n",
    "features.remove('card_id')\n",
    "features.remove('target')\n",
    "    \n",
    "lgbm_data = lgbm.Dataset(train[features], train['target'])\n",
    "\n",
    "bst = lgbm.train(best_clf, lgbm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train_pred = bst.predict(train_LGBMwrapper[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7249551755041335"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(train_LGBMwrapper['target'], lgbm_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_LGBMwrapper['target'] = bst.predict(test_LGBMwrapper[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_LGBMwrapper[['card_id', 'target']].to_csv('submission_lgbm.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(train, test, params):\n",
    "    \n",
    "    features = train.columns.tolist()\n",
    "    features.remove('card_id')\n",
    "    features. remove('target')\n",
    "    \n",
    "    params = params_append(params)\n",
    "    ESR, NBR, VBE = 30, 10000, 50\n",
    "    \n",
    "    prediction_test = 0\n",
    "    cv_score = []\n",
    "    prediction_train = pd.Series()\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "    for train_part_idx, eval_idx in kf.split(train[features], train['target']):\n",
    "        \n",
    "        train_part = lgbm.Dataset(train[features].loc[train_part_idx], train['target'].loc[train_part_idx])\n",
    "        eval_part = lgbm.Dataset(train[features].loc[eval_idx], train['target'].loc[eval_idx])\n",
    "        \n",
    "        bst = lgbm.train(params, train_part, valid_sets=[train_part, eval_part], valid_names=['train', 'eval']\n",
    "                         , early_stopping_rounds=ESR, keep_training_booster=NBR, verbose_eval= VBE\n",
    "                        )\n",
    "        \n",
    "        prediction_train_temp = bst.predict(train[features].iloc[eval_idx])\n",
    "        prediction_train = pd.concat([prediction_train, pd.Series(prediction_train_temp, index = eval_idx)])\n",
    "        prediction_test += bst.predict(test[features])\n",
    "        score = np.sqrt(mean_squared_error(prediction_train_temp, train['target'].iloc[eval_idx]))\n",
    "        cv_score.append(score)\n",
    "        \n",
    "    print('Cross Validation Score:', cv_score, sum(cv_score)/5)\n",
    "    pd.Series(prediction_train.sort_index().values).to_csv('train_lgbmcv.csv', index = False)\n",
    "    pd.Series(prediction_test/5).to_csv('test_lgbmcv.csv', index = False)\n",
    "    test['target'] = prediction_test / 5\n",
    "    test[['card_id', 'target']].to_csv('submission_lgbmcv.csv', index = False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66684\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score -0.389966\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.74192\teval's rmse: 3.86725\n",
      "[100]\ttrain's rmse: 3.70054\teval's rmse: 3.83035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.70054\teval's rmse: 3.83035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66668\n",
      "[LightGBM] [Info] Number of data points in the train set: 161533, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score -0.398532\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.77596\teval's rmse: 3.72424\n",
      "[100]\ttrain's rmse: 3.73272\teval's rmse: 3.69269\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.73272\teval's rmse: 3.69269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66702\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score -0.393677\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.77403\teval's rmse: 3.73309\n",
      "[100]\ttrain's rmse: 3.7319\teval's rmse: 3.69678\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.7319\teval's rmse: 3.69678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66625\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score -0.391203\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.77024\teval's rmse: 3.74775\n",
      "[100]\ttrain's rmse: 3.72773\teval's rmse: 3.71196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.72773\teval's rmse: 3.71196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/keweilu/anaconda3/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66658\n",
      "[LightGBM] [Info] Number of data points in the train set: 161534, number of used features: 300\n",
      "[LightGBM] [Warning] Unknown parameter: bagging_frequency\n",
      "[LightGBM] [Info] Start training from score -0.394803\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 3.76172\teval's rmse: 3.78663\n",
      "[100]\ttrain's rmse: 3.71941\teval's rmse: 3.7518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttrain's rmse: 3.71941\teval's rmse: 3.7518\n",
      "Cross Validation Score: [3.830346032432482, 3.6926875595546895, 3.6967828367011877, 3.7119583893390704, 3.7518000549765107] 3.736714974600788\n"
     ]
    }
   ],
   "source": [
    "train_predict(train_LGBMwrapper, test_LGBMwrapper, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
